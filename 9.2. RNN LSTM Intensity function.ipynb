{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras \n",
    "\n",
    "from tensorflow.keras import Model, metrics, backend\n",
    "\n",
    "from tensorflow.keras.layers import LSTM, Input, Embedding, Dense, Dropout\n",
    "\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and transform values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN inputs -- Transform y_label and perform OneHotEnconding on failure type\n",
    "\n",
    "rnn_inputs_event = np.load('event_set.npy')\n",
    "profile = pd.read_pickle('profile.pickle')\n",
    "profile = profile.drop(columns='unit_ID')\n",
    "\n",
    "scaler_time = MinMaxScaler()\n",
    "d1 = rnn_inputs_event.shape[0]\n",
    "d2 = rnn_inputs_event.shape[1]\n",
    "\n",
    "num_class = np.unique(rnn_inputs_event[:,:,0]).shape[0]\n",
    "rnn_input_onehot = np.array(pd.get_dummies(pd.DataFrame(rnn_inputs_event[:,:,0].reshape(-1,1).astype(str)))).reshape(d1,d2,num_class)\n",
    "rnn_inputs_event = np.concatenate([rnn_input_onehot, rnn_inputs_event[:,:,1:]], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform normalization and dummies for static features\n",
    "\n",
    "scaler_lengte = MinMaxScaler()\n",
    "scaler_age = MinMaxScaler()\n",
    "scaler_appendage = MinMaxScaler()\n",
    "scaler_water_hammer = MinMaxScaler()\n",
    "\n",
    "# test diameters -> categorical or numerical\n",
    "scaler_inw = MinMaxScaler()\n",
    "scaler_nom = MinMaxScaler()\n",
    "\n",
    "profile['LENGTE_GIS'] = scaler_lengte.fit_transform(np.array(profile['LENGTE_GIS']).reshape(-1, 1))\n",
    "\n",
    "profile['Age'] = scaler_age.fit_transform(np.array(profile['Age']).reshape(-1, 1))\n",
    "\n",
    "profile['Aansluiting'] = scaler_appendage.fit_transform(np.array(profile['Aansluiting']).reshape(-1, 1))\n",
    "\n",
    "profile['distance'] = scaler_water_hammer.fit_transform(np.array(profile['distance']).reshape(-1, 1))\n",
    "\n",
    "profile['INWENDIGE_'] = scaler_inw.fit_transform(np.array(profile['INWENDIGE_']).reshape(-1, 1))\n",
    "profile['NOMINALE_D'] = scaler_nom.fit_transform(np.array(profile['NOMINALE_D']).reshape(-1, 1))\n",
    "\n",
    "profile = pd.get_dummies(profile, prefix_sep='_').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val(rnn_inputs_event, profile, p=[0.25, 0.75]):\n",
    "    global x_train_event, y_train_event, x_val_event, y_val_event, profile_train, profile_val\n",
    "    \n",
    "    # Randomization of data file\n",
    "\n",
    "    boolean_train = np.random.choice(a=[False, True], p=p, size=(profile.shape[0],))\n",
    "    boolean_val = b = np.invert(boolean_train)\n",
    "\n",
    "    x_train_event = rnn_inputs_event[:,:-1,:]\n",
    "    y_train_event = rnn_inputs_event[:,:-1,-1]\n",
    "    \n",
    "    x_train_event = rnn_inputs_event[:,:-1,:][boolean_train]\n",
    "    y_train_event = rnn_inputs_event[:,-1:,-1][boolean_train]\n",
    "    x_val_event = rnn_inputs_event[:,:-1,:][boolean_val]\n",
    "    y_val_event = rnn_inputs_event[:,-1:,-1][boolean_val]\n",
    "    profile_train = profile[boolean_train]\n",
    "    profile_val = profile[boolean_val]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return x_train_event, y_train_event, x_val_event, y_val_event, profile_train, profile_val\n",
    "\n",
    "train_val(rnn_inputs_event, profile, [0.25, 0.75])\n",
    "\n",
    "print('Shape x_train: ' + str(x_train_event.shape))\n",
    "print('Shape x_val: ' + str(x_val_event.shape))\n",
    "print()\n",
    "print('Shape y_train: ' + str(y_train_event.shape))\n",
    "print('Shape y_val: ' + str(y_val_event.shape))\n",
    "print()\n",
    "print('Shape profile_train: ' + str(profile_train.shape))\n",
    "print('Shape profile_val: ' + str(profile_val.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(y_train_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE = 'joint'  # Set type of model\n",
    "\n",
    "num_steps = x_train_event.shape[1]\n",
    "event_size =  x_train_event.shape[2]\n",
    "profile_size = profile_train.shape[1]\n",
    "\n",
    "main_input = Input(shape=(num_steps,event_size), dtype='float32', name='main_input')\n",
    "lstm_out = LSTM(32)(main_input)\n",
    "\n",
    "auxiliary_input = Input(shape=(profile_size,), name='aux_input')\n",
    "\n",
    "if TYPE=='joint':\n",
    "    x = keras.layers.concatenate([lstm_out, auxiliary_input])\n",
    "elif TYPE=='event':\n",
    "    x = lstm_out\n",
    "elif TYPE=='profile':\n",
    "    x = auxiliary_input\n",
    "\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "time_stamp = Dense(1, activation='softplus', name='time_stamp')(x)\n",
    "\n",
    "if TYPE=='joint':\n",
    "    model = Model(inputs=[main_input, auxiliary_input], outputs=[time_stamp])\n",
    "elif TYPE=='event':\n",
    "    model = Model(inputs=[main_input], outputs=[time_stamp])\n",
    "elif TYPE=='profile':\n",
    "    model = Model(inputs=[auxiliary_input], outputs=[time_stamp])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# And trained it via:\n",
    "model.fit({'main_input': x_train_event, 'aux_input': profile_train},\n",
    "          {'time_stamp': y_train_event},\n",
    "          epochs=30,\n",
    "          batch_size=64,\n",
    "          verbose=2,\n",
    "          validation_data=({'main_input': x_val_event, 'aux_input': profile_val},\n",
    "          {'time_stamp': y_val_event}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print('\\n# Evaluate on test and validation data')\n",
    "results_train = model.evaluate({'main_input': x_train_event, 'aux_input': profile_train},\n",
    "          {'time_stamp': y_train_event}, batch_size=32,\n",
    "          verbose=0)\n",
    "\n",
    "results_val = model.evaluate({'main_input': x_val_event, 'aux_input': profile_val},\n",
    "          {'time_stamp': y_val_event}, batch_size=32,\n",
    "          verbose=0)\n",
    "\n",
    "print('Loss value on test set: ' + str(results_train[0]) + ' | Accuracy (MAE) on test set: ' + str(results_train[1]))\n",
    "print('Loss value on validation set: ' + str(results_val[0]) + ' | Accuracy (MAE) on validation set: ' + str(results_val[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict({'main_input': x_val_event, 'aux_input': profile_val})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
